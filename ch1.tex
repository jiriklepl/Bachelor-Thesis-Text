\chapter{Functional programming with types}

Describing lambda calculus is important in both the context of type inference and in the context of (functional)
programming as a whole.

In this thesis we will use lambda calculus as described in Introduction to Lambda Calculus.  % TODO: insert something ABOUT LC

Lambda calculus is formally described as:

$variable ::= 'v' | variable ''' \\ \lambda\mbox{-}term ::= variable | '(' \lambda\mbox{-}term\ \lambda\mbox{-}term ')' |  '(\lambda' variable\ \lambda\mbox{-}term ')'$

% TODO: insert rules for LC

It is a simple language in which we can formally describe any computational problem.

Choosing lambda calculus, or its derivatives might seem counterintuitive at first, because it
is not very efficient in expressing imperative ideas like mutability for example, but for
purposes of type inference we don't need to know the actual meaning of the code (like for example
if a loop stops), we can just limit ourselves to modelling type dependencies in the program and
everything on top of that is just for human readability, debugging purposes, demonstration and
primarily for possible extension.

Lambda calculus can quite easily model any C program, but one has to be careful at distinguishing
between initialization and assignment as initialization creates binding (in lambda calculus expressed
as substitution for a bound variable in an abstraction) and assignment is a function that takes two
expressions of the same type and returns the first (here we demonstrate that we don't need to
model the whole behavior of the program, because copying of the value doesn't have any effect on
the types of the arguments).

Here we will use $\lambda_C$ to denote transformation from C to lambda calculus,
this transformation can be actually done in a multiple of ways, but in this thesis we will use one that tries to
reflect the structure of the original code as closely as possible.

Models of some C constructs can be as follows (grammar taken from ): % TODO: http://www.quut.com/c/ANSI-C-grammar-y.html

$\lambda_C\left(additive\_expression '+' multiplicative\_expression\right) = \\ plus_C (\lambda_C additive\_expression) (\lambda_C multiplicative\_expression)$

This example demonstrates the most simple case where  where we can model the C construct "one to one",
but there are more tricky examples like the following one:

$\lambda_C\left(declaration\_specifiers IDENTIFIER '=' initializer\right) = \\ (\lambda IDENTIFIER : \lambda_C(declaration\_specifiers) .\ \dots) (\lambda_C initializer)$

Initialization creates binding (as stated before) so we have to model that by creating a new abstraction and put the whole
part of the function's body that follows inside this abstraction (this in effect means that all the return values of these nested functions
and of the function which contains them will share the same type), a similar thing are switch statements where the switch "call" can be modeled
as an initialization to an anonymous variable and the single case statements as assignments to this variable.

\section{Simply-typed lambda calculus}

Just lambda calculus wouldn't be good enough for modeling type inference of the proposed language (We will call it CHM from now on).
% TODO: clean up this "from now on", it should be in the very top
So we need to introduce typed lambda calculi.

Simply-typed lambda calculus, described by Church, is one of the first % TODO: the very first? also: add some more info on church
lambda calculi with type system. Typing of lambda terms helps checking the validity of the program, protecting us from writing
programs that make little sense like for example adding amperes and volts % TODO: intro to lambda
and also it makes it easier to think about the program in the bigger picture giving us information about usage of the typed entities
in some code, typing $f : \alpha \rightarrow \alpha \rightarrow \alpha$, for example, tells us that $f$ is a function taking two arguments
of some type and returning a value of the same type and from that alone we can assume that applying two parameters of the same type on it
should be well-defined.

% TODO: add the stuff about variables and syntax and sh like that, also the ,\-> name and stuff, also typing

\subsection{Simply-typed lambda calculus deriving rules}

Simply-typed lambda calculus uses the following rules:

variable:
$\dfrac{x : \tau \in \Gamma}{\Gamma \vdash x : \tau}$

application:
$\dfrac{\Gamma \vdash e : \sigma \rightarrow \tau \  \Gamma \vdash x : \sigma}{\Gamma \vdash e x : \tau}$

abstraction:
$\dfrac{\Gamma, x : \sigma \vdash e : \tau}{\Gamma \vdash \lambda x . e : \sigma \rightarrow \tau}$

We call $\gamma$ either a basis, a context, or a set of assumptions. These names describe pretty well its meaning, in simply-typed lambda calculus it
is a set of typings we derive the rest of typings from.

The syntax of the rules describes step-by-step derivation of types where the bottom one follows the top one.

% TODO: check it
Example for $id = \lambda x . x$:

\begin{listing}
    \item $\{\} \vdash \lambda x . x : ?$
    \item $\{x : \tau\} \vdash x : \tau$ (var)
    \item $\{\} \vdash \lambda x . x : \tau \rightarrow \tau$ (abstraction) from (2), this solves (1)
\end{listing}

Notice here the context changes during the derivation process, so we can give typing to $\lambda\rightarrow$ terms without any context
and they can have different typings in different contexts, also one term can have multiple possible typings.

% TODO: maybe say something about church vs curry style and also unification and stuff

One thing that is a problem for the simply-typed lambda calculus is that it is not turing complete, % TODO: reference a paper that says so
because it is strongly normalizing and thus the type inference would have to solve the halting problem,
this problem will be answered by the following type systems.

\subsection{principal typing}

Every typeable term $e$ in simply-typed lambda calculus has principal type $\tau$ which is computable from $e$ and every other typing
$e : \sigma$ in the same context is a result of some type substitution $[\overline{\alpha} := \overline{\pi}]$, here we use the overlined symbols
as an shortcut for many atomic substitutions $[\alpha := \pi]$, where $\pi$ is a type and $\alpha$ an type variable, this will be very important
later when we introduce more advanced type systems as principal type of $e$ is the only information about $e$ we have to consider
when we see $e$ again as a subterm of some term $e'$ to check $e'$' typability (for typability see below). % TODO: elaborate / provide source, check and correct

We can think of it as that the principal typing of $e$ is a typing general enough to be substitutable into all other possible typings of $e$
but not general enough to be substitutable into any impossible typings, this is usually simplified into "the most general type of $e$". % TODO: language and style

The example just above % TODO: maybe use fig notation
is great fit for showing this as for example $\lambda x . x : \sigma$ would be a possible typing, but not a principal one, because
$\alpha \rightarrow \alpha \rightarrow \alpha$ would give use $\alpha \sim \alpha \rightarrow \alpha$, which would give us an incomputable
infinite type.

\subsubsection{type instances}

We will call a type $\tau$ an instance of a type $\sigma$ if there is a type substitution $[\overline{\alpha} := \overline{\pi}]$
that transforms $\sigma$ into $\tau$ % TODO: do some editing

\subsection{Type checking, typability and type inference}

Type checking is the process of validating whether a term can have a given type
whereas typability is whether the term can be given some type.

Type inference is closely related to typability but has an additional requirement of giving an actual type for the term, and furthermore
usually what we are interested in is the principal type.

Both type checking and typability of the simply-typed lambda calculus is decidable and its type inference is computable. % TODO: add reference, check wording

\section{F systems and parametric polymorphism} % TODO: TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO

% TODO: add reference or I don't know
System F, polymorphic lambda calculus, or second-order lambda calculus (from the idea of quantifying types) introduces
parametric polymorphism into the lambda calculus. Here we can reuse the example of $id = \lambda x . x$ which can have many typings
$id : \tau \rightarrow \tau$ which we can state by:

$id : \forall \alpha . \alpha \rightarrow \alpha$

We call terms like $id$ beginning with $\forall$ \textbf{polymorphic} (opposed by \textbf{monomorphic}).

System F uses the rules of the simply-typed lambda calculus, plus the following:

\begin{itemize}
    \item[$\forall$-elimination] $\dfrac{\Gamma \vdash e : \forall \alpha . \sigma}{\Gamma \vdash e : \sigma [\alpha := \tau]}$
    \item[$\forall$-introduction] $\dfrac{\Gamma \vdash e : \sigma}{\Gamma \vdash e : \forall \alpha . \sigma}$
\end{itemize}

In (2) $\alpha$ is not free in any any assumptions on which the premise $e : \sigma$ depends. % TODO: introduce the terms judgement, premise, assumption

System F is still strongly normalizing and thus not turing complete. % TODO: consider rewriting/scrapping this

In system F the type checking is undecidable and thus any general type inference algorithm is impossible.
The Hindley-Milner type system is a restriction of it % TODO: elaborate on undecidability of F etc.
that allows for easy type inference algorithm we will base ours on.

\section{Hindley-Milner type system}

The Hindley-Milner type system, we will refer to it simply as HM, is a fairly minimalistic extension of lambda calculus terms being of a form

$expression ::= variable | expression expression | \lambda variable . expression | let variable = expression in expression$

(It differs from the lambda calculus only in the third clause). Semantics of this clause $let x = e in e'$ are the same as in
$e'[x := e]$, note that this differs from $(\x . e') e$ where all occurrences of $x$ have the same typing. % TODO: oh gosh

% FIXME: continue from here pleeeeaaaaase

\section{Hindley-Milner polymorphism}

(As described in PTSfPwOaS).
Pure HM allows for just parametric polymorphism without any ad-hoc polymorphism
or subtyping, this means there is one principal type for every symbol in the program and it has just one definition, this is useful in cases
where an algorithm works on any types of its algorithms, good example of that would be swapping the values of two pointers (this algorithm cannot
take advantage of knowing the exact type unless we take into consideration some really nontraditional architectures).

We will then break this one
rule by introducing type classes and type families, two ideas with the same basis where we put constraints on types and we can
create non-overlapping instances for them, or we can put these constraints on a regular symbol to denote that the algorithm either works only on
some types or doesn't make sense on others, this is especially useful in static analysis of the code.

Other solutions of this are overloading and subtyping, but the type inference of the most common form of overloading is undecidable
as described by, so overloading wouldn't be a good solution in our case. % TODO: NP overload

It also contradicts the idea of parametric polymorphism used in this thesis, where every implementation of an function can be
described as a proof of a special case of a theorem described by the principal type of the function and this type is therefore
valid for all its implementations.

Subtyping % TODO: finish this (subtyping)

\section{Overloading with type classes}

Type classes, as stated above, are good for stating an algorithm makes sense only for some types or that it requires a different implementation for
different types, usually to enhance performance by writing specialized algorithms for common or critical types instead of writing a general slow algorithm,
this was the main motivation behind developing those, % TODO
viz different physical instructions for comparing common numeric values.

Usefulness of classes can be shown on `Ord', this constraints requires that two variables of type $\alpha$ s.t. $Ord(\alpha)$, we can say `$\alpha$ is (in) Ord'.
But not everything can be partially ordered, take directed graphs, for example, where the reachability of one vertex from another is in `Ord' only
if the graph is a directed acyclic graph, in which case we can use algorithms expecting `Ord' on problems concerning reachability, but not otherwise.

`Ord' can also show how we could want different instances for different types.
Let's say `Ord' has one method $<=$ of type $a -> a -> Bool$ with the expected behavior. % TODO: explain a method

For two `Int's we just compare them and return whether the first is lower than the other,
but if we have, let's say `Customer's, with different Id numbers as keys in some map (or dictionary) then we don't need to compare whole customers,
but just their Ids.

method: a function which is defined inside a class and is expected to be instantiated alongside the class. % TODO

\xxx{zhruba popsat jak to vysvihnul \citet{jones1999typing}.}

\xxx{test normalni citace: \cite{jones1999typing}.}

\section{Haskell type system}

Haskell uses kind system % TODO: finish this (kind system)

\xxx{Teoretickej skok do budoucnosti --- mirnej review o tom jak se to ve skutecnosti dela v haskelu. Treba ukazat ze MPTCs jsou nerozhodnutelny protoze umej simulovat prolog.}
